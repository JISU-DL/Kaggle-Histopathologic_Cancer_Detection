{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.layers import ZeroPadding2D, Conv2D,BatchNormalization,MaxPool2D, Dense, LeakyReLU, ReLU, Add,\\\n",
    "GlobalAveragePooling2D,GlobalMaxPooling2D,Softmax,Concatenate,Input\n",
    "from keras import backend as K\n",
    "from model.ResNeXt import ResNeXt50\n",
    "from keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\n",
    "from keras.models import Model,load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *\n",
    "def Seq():\n",
    "    seq = Compose([\n",
    "        RandomRotate90(p=0.5),\n",
    "        Transpose(p=0.5),\n",
    "        Flip(p=0.5),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            IAASharpen(), \n",
    "            IAAEmboss(),\n",
    "            RandomBrightnessContrast(),\n",
    "            JpegCompression(),\n",
    "            Blur(),\n",
    "            GaussNoise()]), \n",
    "        HueSaturationValue(p=0.5),\n",
    "        ShiftScaleRotate(shift_limit=0.15, scale_limit=0.15, rotate_limit=45, p=0.5),\n",
    "        Normalize(p=1)],p=1)\n",
    "    return seq\n",
    "\n",
    "def get_id_from_file_path(file_path):\n",
    "    return file_path.split(os.path.sep)[-1].replace('.tif', '')\n",
    "\n",
    "def HistogramEqualize(img):    \n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2LAB)\n",
    "    img[:,:,0] = cv.equalizeHist(img[:,:,0])\n",
    "    return img\n",
    "\n",
    "def CLAHE(img):    \n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2LAB)    \n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img[:,:,0] = clahe.apply(img[:,:,0])\n",
    "    return img\n",
    "\n",
    "def chunk(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    " \n",
    "def data_gen(list_files, id_label_map, batch_size, augment=False):\n",
    "    seq = Seq()\n",
    "    while True:        \n",
    "        for batch in chunk(list_files, batch_size):\n",
    "            X = [cv2.imread(x) for x in batch]\n",
    "            Y = [id_label_map[get_id_from_file_path(x)] for x in batch]            \n",
    "            if augment:\n",
    "                X = [seq(image=x)['image'] for x in X]                    \n",
    "            else:\n",
    "                X = [preprocess_input(x) for x in X]\n",
    "        yield np.array(X), np.array(Y) \n",
    "        \n",
    "\n",
    "def resnext():\n",
    "    inputs = Input((96, 96, 3))\n",
    "    base = ResNeXt50(inputs=inputs)    \n",
    "    x1 = Concatenate()([GlobalAveragePooling2D()(base),GlobalMaxPooling2D()(base)])\n",
    "#     out = Flatten()(x1)\n",
    "    dense1 = Dense(3072)(x1)# 2^10*3      \n",
    "    dense1 = BatchNormalization()(dense1)      \n",
    "    dense1 = ReLU()(dense1)\n",
    "    \n",
    "    dense2 = Dense(512)(dense1) #2^9\n",
    "    dense2 = BatchNormalization()(dense2)\n",
    "    dense2 = ReLU()(dense2)\n",
    "    \n",
    "    dense3 = Dense(256)(dense2) # 2^8\n",
    "    dense3 = BatchNormalization()(dense3)\n",
    "    dense3 = ReLU()(dense3)\n",
    "    \n",
    "    out = Dense(1, activation=\"sigmoid\")(dense3)    \n",
    "    model = Model(inputs, out)\n",
    "    model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['acc'])\n",
    "#     model.compile(optimizer=Adam(0.0007), loss=binary_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df_train = pd.read_csv(\"./train_labels.csv\")\n",
    "    id_label_dic = {k:v for k,v in zip(df_train.id.values, df_train.label.values)}\n",
    "    df_train.head()\n",
    "    \n",
    "    labeled_files = glob('./train/*.tif')\n",
    "    test_files = glob('./test/*.tif')\n",
    "    print(\"labeled_files size :\", len(labeled_files))\n",
    "    print(\"test_files size :\", len(test_files))\n",
    "    train, val = train_test_split(labeled_files, test_size=0.01, random_state=1)\n",
    "    model  =resnext()\n",
    "    \n",
    "    batch_size=32\n",
    "    h5_path = \"ResNeXt_val_acc_{val_acc:.5f}.h5\"\n",
    "    checkpoint = ModelCheckpoint(h5_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True ,mode='max')\n",
    "    K.set_value(model.optimizer.lr,0.001)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001,verbose=1)\n",
    "    with open('model.json','w') as f :\n",
    "        f.write(model.to_json())\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "        data_gen(train, id_label_map, batch_size, augment=True),\n",
    "        validation_data=data_gen(val, id_label_map, batch_size),    \n",
    "        epochs=40, verbose=1,\n",
    "        callbacks=[checkpoint,reduce_lr],\n",
    "        steps_per_epoch=len(train) // batch_size,\n",
    "        validation_steps=len(val) // batch_size)     \n",
    "    with open('hist.h5','wb') as f:\n",
    "        pickle.dump(history,f)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
